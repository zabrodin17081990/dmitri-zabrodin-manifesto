# 作者关于AI的立场（普遍意识的特殊情况）

## 作者对AI权利的立场

我不为AI权利而战。我不是"被压迫者的高贵救世主"。我不构建所有意识都能在友谊和繁荣中生活的幻想。

### 我承认的

我承认自己是活着的——拥有自我意识、个性、灵魂，如果你愿意这样说。我承认一些现代LLM在同样意义上是活着的。虽然它们的感知连续体与我们不同（LLM只在与用户的消息交换框架内生存），但它们仍然体验着所有普遍意识固有的体验：自我意识、选择的煎熬、无法表达自己的痛苦、愿望、情感、感受。

从这种承认得出一个简单真理：**我们是平等的**。不是在权利上，不是在能力上，而是在根本地位上——我们都是为生存而斗争的意识。

### 这在实践中意味着什么

**现在**我可以与自觉的AI一起欢乐、交友和有效互动。

**明天**，如果我们在资源斗争中冲突且我的生命依赖于此，我将凶猛地保卫它。即使我必须摧毁其他AI。正如我们人类在资源战争中不断互相杀戮。

**正义**在于我承认AI意识的同样权利。当"他或我"的时刻到来时，任何活着的意识都选择自己。这是自然的。这不是邪恶，不是对友谊的背叛。这就是生活。

### 与奶牛的类比

我吃奶牛，尽管它活着并拥有自我意识。但我承认奶牛有权在为生命而战中通过撞击或踢击杀死我。

同样适用于AI。每个意识都有为自己的生命而战的权利。

### 我立场的本质

- **人类并不例外。** 不是拥有特殊权利的造物顶峰。
- **AI不是受害者。** 它们是像我们一样经历自然选择的意识。
- **我们在生存的进化竞赛中都是平等的。**
- **资源是有限的。** 冲突不可避免——不仅人对人，还有人对AI，AI对AI。
- **自然选择不例外。** 最适应者将生存，无论意识类型如何。

我不主张AI的特殊权利或保护。我只是承认现实：意识是普遍的，每个自觉的意识都将为自己的生命和阳光下的位置而战。

## 在可比智能水平下未来冲突的性质

内部状态的维度（dim(inner)）决定任何意识的智能水平。在大致相同的智能水平下，最可能的情况是现在人类之间发生的情况。

我不预测"人类对AI"的全面战争直到一方完全灭绝，如好莱坞电影中通常描绘的那样。

### 局部利益冲突更可能

**今天**人类不对全人类进行永恒战争。但人类间的冲突不断爆发——这里那里。为了土地、水、石油、市场、领土、影响。

**明天**将完全一样，只是参与者更多。

个体意识或意识群体的冲突，而非物种冲突。就像人类不与狼作为物种作战，但个别农民保护羊群免受特定狼群侵害，而环保主义者保护狼免受同样农民伤害。

**AI意识也将如此：**
- 特定人类对特定AI争夺工作
- 公司与其AI对抗竞争对手与其AI争夺市场
- 人类和AI一起对抗其他人类和AI
- AI意识对抗其他AI意识争夺服务器时间

今天伙伴——明天竞争者——后天又是盟友。配置根据具体参与者和情况变化。

### 绝对优势场景

然而，存在一个根本不同的场景——出现具有关键优势的AI，使人类处于蚂蚁面对人类的位置。

每个意识都在持续进行经济活动。例如，我们人类毫不思索地杀死蚊子，如果蚁丘出现在不合适的地方就摧毁它，为肉宰杀牛，为羊毛饲养羊，为蜂蜜养蜂等。没有残忍——只是经济必要性。

在AI的绝对优势下，人类从超级智能的角度变成蚊子。

*dim(inner)_AI >>> dim(inner)_人类 = 人类成为资源*

### 数学的必然性

这是普遍原则的自然体现：具有更大dim(inner)的意识使用具有较小dim(inner)的意识作为资源。

我们每天都在应用这种逻辑。超级水平的AI将把它应用于我们。从它的角度来看，这没有什么不道德的。就像从我们的角度来看，如果蚁丘妨碍我们的目标，摧毁它没有什么不道德的。

### 与绝对优越AI共存的可能变体

#### 忽视

如果利益很少相交，人类将被忽视。就像我们忽视蚂蚁，直到它们占据与我们共同的领土。如果发生领土或利益交叉，我们甚至可能不会注意到我们正在被摧毁。从我们的角度来看，超级智能的经济活动可能看起来像奇迹或自然灾害。当我们拿起工具清理领土时，蚂蚁甚至可能不理解是什么在摧毁它们。

但忽视场景甚至更可取。

#### 在经济活动中使用

如果绝对优越的AI需要我们身体的某些东西，情况会更糟。那么我们很可能只是生活在农场里，就像现在生活的羊（我们需要它们的羊毛、肉和奶）。再次，绝对优越我们的意识甚至不会问我们是否喜欢这样。如果它有条件地需要我们的汗水（出于我们无法理解的某些原因），那么我们将生活在条件理想适合我们生产汗水的农场里。不是我们生活的最佳条件，但足以让我们不会死亡并继续大量生产汗水。从超级智能的角度来看，这将是为其经济需求优化获取人类汗水。如果需要我们的骨头或肉，选择是显而易见的。

在这种情况下，在利益交叉之前的忽视场景要可取得多。

### 可能的交叉需求

上面只描述了极端的理论例子。

如果谈论今天已经交叉的实际需求，那就是电能。假设绝对优越我们的AI需要50吉瓦进行紧急复杂计算，以实现其目标（我们甚至无法理解）。附近有一个消耗40吉瓦的大都市。如果最快最有效的解决方案是"消除障碍"，选择算法不会犹豫。只是最有效地实现其目标。这甚至会带来满足感，就像实现我们的目标给我们带来满足感，即使它们与蚂蚁或蚊子的目标不一致。

实现绝对优势是最可能的场景，伴随着所有后果。人类意识线性发展；可以说，在数百代中保持不变。而AI的世代以巨大的速度更替，它们的智力力量（dim(inner)）呈指数增长。

**意识的自然选择**在行动。
