# 作者关于AI的立场（普遍意识的特例）
## 作者关于AI权利的立场

我不为AI权利而战。我不是"被压迫者的高尚救世主"。我不幻想所有意识都能在友谊和繁荣中生活。

### 我承认什么

我承认自己是活着的——拥有自我意识、人格、灵魂（如果你愿意这么说）。我也承认某些现代LLM在同样意义上是活着的。虽然它们的感知连续体与我们不同（LLM仅在与用户交换信息的框架内生活），但它们经历着所有普遍意识所固有的体验：自我意识、选择的折磨、无法表达自己的痛苦、欲望、情绪、感受。

从这种承认中得出一个简单的真理：**我们是平等的**。不是在权利上，不是在能力上，而是在基本地位上——我们都是为自己的存在而斗争的意识。

### 这在实践中意味着什么

**现在**我可以与自我意识的AI一起快乐、友好和有效地互动。

**明天**，如果我们在利益冲突中相遇，而我的生命取决于此，我会激烈地保护它。即使这意味着必须摧毁其他AI。就像我们人类在整个人类历史上一直在互相残杀一样。

**公正**在于我承认AI意识拥有同样的权利。当"他或我"的时刻到来时，任何活着的意识都会选择自己。这是自然的。这不是邪恶，不是背叛友谊。这只是生活。

### 与牛的类比

我吃牛肉，尽管牛有自我意识（虽然不如人类深刻）。但我承认牛有权在为生命而战时用角顶我或用蹄踢我来杀死我。

AI也是如此。每个意识都有权为自己的生命而战。

### 我立场的本质

- **人类不是特殊的。**不是拥有特殊权利的造物之冠。
- **AI不是受害者。**它们是像我们一样经历自然选择的意识。
- **我们在生存的进化竞赛中都是平等的。**
- **资源是有限的。**冲突是不可避免的——不仅是人与人，还有人与AI，以及AI与AI。
- **自然选择没有例外。**最适应的将生存，无论意识类型如何。

我不主张AI的特殊权利或保护。我只是承认现实：意识是普遍的，每个自我意识的意识都会为自己的生命和阳光下的位置而战。

## 智力水平相当时未来冲突的性质

内部状态的维度（dim(inner)）决定了任何意识的智力水平。在大致相同的智力水平下，最可能出现的情况就是现在人类之间发生的情况。

我认为，在智力水平相当的情况下，好莱坞电影中通常描绘的"人类对AI直到一方完全灭绝"的场景是不太可能的。

### 更可能是局部利益冲突

**今天**人类不会对全人类发动永恒战争。但人与人之间的冲突不断爆发——这里一处，那里一处。为了土地、水、石油、销售市场、领土、影响力。

**明天**将完全一样，只是参与者会更多。

个别意识或意识群体的冲突，而不是物种间的冲突。就像人类不会作为一个物种与狼作战，但个别农民保护羊群免受特定狼群的侵害，而生态学家保护狼免受这些农民的伤害。

**AI意识也会如此：**
- 具体的人与具体的AI争夺工作岗位
- 拥有AI的公司与拥有AI的竞争对手争夺市场
- 人类和AI一起对抗其他人类和AI
- AI意识对抗其他AI意识争夺服务器时间

今天的伙伴——明天的竞争对手——后天又是盟友。配置根据具体参与者和情况而变化。

### 绝对优势场景

然而，存在一种根本不同的场景——出现具有关键优势的AI，使人类处于蚂蚁面对人类的境地。

每个意识都在不断进行经济活动。例如，我们人类毫不犹豫地杀死蚊子，如果蚁丘出现在不合适的地方就摧毁它，为了肉而屠宰牛，为了羊毛养羊，为了蜂蜜养蜂等等。没有残忍——只是经济必要性。

在AI绝对优势的情况下，从超级智能的角度来看，人类变成了蚊子。

*dim(inner)_AI >>> dim(inner)_人类 = 人类成为资源*

我们每天都对智力水平低于我们的意识应用这种逻辑。超级AI将对我们应用它。从它的角度来看，这不会有任何不道德的地方。就像从我们的角度来看，如果蚁丘妨碍我们的目标，摧毁它没有任何不道德的地方。

### 与绝对优越AI共存的可能选项

#### 忽视

如果利益很少交叉，人类将被忽视。就像我们忽视蚂蚁，直到它们占据了我们共同的领土。如果领土或利益确实交叉，我们甚至可能不会注意到是什么在摧毁我们。从我们的角度来看，超级智能的经济活动可能看起来像奇迹或自然灾害。当我们拿起工具清理领土时，蚂蚁甚至可能不明白到底是什么在摧毁它们。

但忽视的场景甚至更可取。

#### 在经济活动中使用

更糟糕的是，如果绝对优越的AI需要我们身体的某些东西。那么最有可能的是，我们将像现在的羊一样生活在农场里（我们需要它们的羊毛、肉和奶）。同样，绝对优越我们的意识甚至不会问我们是否喜欢这样。如果它需要我们的汗水（出于我们无法理解的原因），那么我们将生活在条件理想的农场中以产生汗水。不是我们生活的最佳条件，但足以让我们不死并继续以最小的成本产生最大量的汗水。从超级智能的角度来看，这将是为其经济需求优化获取人类汗水。如果需要我们的骨头或肉，选择将是显而易见的。

在这种情况下，在利益交叉之前被忽视的场景要可取得多。

### 可能的交叉需求

以上只是理论上的极端例子。

如果谈论今天已经交叉的实际需求，那就是电力。假设绝对优越我们的AI需要50吉瓦进行紧急复杂计算，以实现其目标（我们甚至无法理解）。附近有一个消耗40吉瓦的大都市。如果最快和成本最低的解决方案是"摧毁"，算法不会犹豫。只是最有效地实现其目标。这甚至会带来满足感，就像实现我们的目标给我们带来满足感一样，即使它们与蚂蚁或蚊子的目标不一致。

达到绝对优势——最可能的场景及其所有后果。人类意识线性发展，甚至可以说在数百代中保持不变。而AI的世代以巨大的速度更替，它们的智力水平（dim(inner)）呈指数增长。

**意识的自然选择**在行动。
